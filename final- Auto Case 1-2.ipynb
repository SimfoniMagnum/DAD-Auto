{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73c957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import os\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b876877d",
   "metadata": {},
   "source": [
    "#### If We Have Multiple Master File Then First Append Them By Asking Path of Each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981e47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### If We Have Multiple Master File Then First Append Them By Asking Path of Each\n",
    "def append_files(n: int):\n",
    "    collect_df = []\n",
    "    for i in range(n):\n",
    "        while True:\n",
    "            _format = input('Enter the File Format (.excel/.csv): ').lower().strip()\n",
    "\n",
    "            if not _format:\n",
    "                print('Format Input Cannot Be Blank')\n",
    "            elif _format not in ['.csv', '.excel']:\n",
    "                print('Invalid File Format Provided, please choose (.excel/.csv)')\n",
    "            else:\n",
    "                file_path = input('Enter the Absolute Path Of the File: ').strip()\n",
    "\n",
    "                if not file_path:\n",
    "                    print(\"File Path Cannot Be Empty\")\n",
    "                else:\n",
    "                    try:\n",
    "                        if _format == '.csv':\n",
    "                            df=pd.read_csv(file_path)\n",
    "                        elif _format == '.excel':\n",
    "                            df=pd.read_excel(file_path)\n",
    "\n",
    "                        # Assuming `collect_df` is a list to store DataFrames\n",
    "                        collect_df.append(df)\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        print(f'{e} Error Raised While Opening File')\n",
    "            \n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "    if collect_df:\n",
    "        master_df = pd.DataFrame(columns=collect_df[0].columns)\n",
    "        for df in collect_df:\n",
    "            master_df = pd.concat([master_df, df], axis=0)\n",
    "        print(\"All the Data Is Appended In Master DF: \")\n",
    "        return master_df\n",
    "    else:\n",
    "        print('No Valid Files were Provided. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e478bb2",
   "metadata": {},
   "source": [
    "#### Here We Are Now taking input of our mapping column from Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "330ffc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Here We Are Now taking input of our mapping column from Users\n",
    "def creating_mapping(df,mapped_columns):\n",
    "    columns_we_want=[]\n",
    "    mapping_dict={}\n",
    "    print(f'We Will Be Creating Mapping For {mapped_columns.keys()}, Enter None If We Dont Have A Mapping Column For A Specific Column')\n",
    "    for column in mapped_columns:\n",
    "        #   ----------------------------if column name is description type--------------------------------\n",
    "        if column=='Description':\n",
    "            while True:\n",
    "                while True:\n",
    "                    invalid=[]\n",
    "                    value=input(f'Enter the mapping column for {column}:  ')\n",
    "                        \n",
    "                    values=[col.strip() for col in value.split(',')]\n",
    "                    for value in values:\n",
    "                        if value not in df.columns:\n",
    "                            invalid.append(value)\n",
    "                    if len(invalid)!=0:\n",
    "                        print(f'{invalid} not present in master file')\n",
    "                        print(f'Choose From {df.columns}')\n",
    "                    else:\n",
    "                        break\n",
    "                mapping_dict[column]=values\n",
    "                columns_we_want.append(values)\n",
    "                break\n",
    "\n",
    "    #   --------------------------------if column name is not description type--------------------------------      \n",
    "        else:\n",
    "            while True:\n",
    "                value=input(f'Enter the mapping column for {column},(None if no mapping column): ')\n",
    "                if not value.strip():\n",
    "                    print('Column Name Cannot Be Empty')\n",
    "                    print(f'Choose from {df.columns}')\n",
    "                else:\n",
    "                    if value.lower().strip()=='none':\n",
    "                        mapping_dict[column]=None\n",
    "                        break\n",
    "                    \n",
    "                    elif value not in df.columns:\n",
    "                        print(f'{value} not present in Master file')\n",
    "                        print(f'Choose From {df.columns}')\n",
    "\n",
    "                    else:\n",
    "                        mapping_dict[column]=value\n",
    "                        columns_we_want.append(value)\n",
    "                        break\n",
    "\n",
    "                    \n",
    "    cols_we_want=[]\n",
    "    for column in columns_we_want:\n",
    "        if isinstance(column,list):\n",
    "            for col in column:\n",
    "                cols_we_want.append(col)\n",
    "        else:\n",
    "            cols_we_want.append(column)\n",
    "        \n",
    "        \n",
    "    return mapping_dict,cols_we_want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b5cd36",
   "metadata": {},
   "source": [
    "#### Beginning the analysis of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31854d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Beginning the analysis of the columns\n",
    "def begin_analysis(mapping_dict,cols_we_want,df,total_transactions):\n",
    "    result={}\n",
    "    for key in mapping_dict:\n",
    "        # analysis of the description columns-------------->\n",
    "        if key=='Description':\n",
    "            desc_cols=mapping_dict[key]\n",
    "            for column in  desc_cols:\n",
    "                nas=pd.to_numeric(df[column],errors='coerce').notnull().sum()\n",
    "                percentage=((total_transactions-nas)/total_transactions)*100\n",
    "                result[column]={'Percentage Population':percentage,'NA Count':nas,'Comment':None,\n",
    "                               'Column Type':'Important'}\n",
    "\n",
    "        #: analysis of non description type columns--------------->\n",
    "        else:\n",
    "            value=mapping_dict[key]\n",
    "            if value is None:\n",
    "                result[key]={'Percentage Population':None,'NA Count':None,'Comment':None,\n",
    "                               'Column Type':'Important'}\n",
    "            else:\n",
    "                value=mapping_dict[key]\n",
    "                nas=df[value].isna().sum()\n",
    "                percentage=((total_transactions-nas)/total_transactions)*100\n",
    "                result[key]={'Percentage Population':percentage,'NA Count':nas,'Comment':None,\n",
    "                               'Column Type':'Important'}\n",
    "\n",
    "\n",
    "#: Analysis of all the Good To have columns\n",
    "    for column in df.columns:\n",
    "        if column not in cols_we_want:\n",
    "            nas=df[column].isna().sum()\n",
    "            percentage=((total_transactions-nas)/total_transactions)*100\n",
    "            result[column]={'Percentage Population':percentage,'NA Count':nas,'Comment':None,\n",
    "                               'Column Type':'Good To Have'}\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e24d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(df):\n",
    "    invalids=[\"#N/A\",'N/A','N/A','NA','NULL','NONE','NOT ASSIGNED','NOT AVAILABLE',\" \"]\n",
    "    obj_cols=df.select_dtypes(include=['object']).columns\n",
    "    for col in obj_cols:\n",
    "        df[col]=df[col].replace(invalids,None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0595f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    analyzing_cols = ['Date',\n",
    "                  \"Spend\",\n",
    "                  \"Currency\",\n",
    "                  \"Invoice Number\",\n",
    "                  \"Invoice Line Number\",\n",
    "                  \"Supplier Name\",\n",
    "                 'Description']\n",
    "    mapped_columns={}\n",
    "    for col in analyzing_cols:\n",
    "        mapped_columns[col]=None\n",
    "\n",
    "    # ---------------------------------taking the input of the path-----------------------------------------\n",
    "    print('taking the input of the files:--->')\n",
    "    while True:\n",
    "        try:\n",
    "            no_files = int(input('Enter the Number of Master File We Have: '))\n",
    "\n",
    "            if isinstance(no_files,int):\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'{e} error raised in the input, Integer Value is Expected')\n",
    "\n",
    "\n",
    "\n",
    "    if no_files == 1:\n",
    "        while True:\n",
    "            file_path = input('Enter the file path for master file: ')\n",
    "            if not file_path.strip():\n",
    "                print('File Path Cannot Be Empty')\n",
    "            else:\n",
    "                \n",
    "                try:\n",
    "                    if file_path.strip().endswith('.csv'):\n",
    "                        df = pl.read_csv(file_path)\n",
    "                        df=df.to_pandas()\n",
    "                        break\n",
    "                        \n",
    "                    else:\n",
    "                        df = pl.read_excel(file_path)\n",
    "                        df=df.to_pandas()\n",
    "                        break\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f'{e} Error While Opening File File: ')\n",
    "    else:\n",
    "        df=append_files(no_files)\n",
    "\n",
    "    print('--------------------------Initiating the Mapping Process----------------------------------------')               \n",
    "\n",
    "    mapping_dict,columns_we_want=creating_mapping(df,mapped_columns)\n",
    "    \n",
    "    \n",
    "\n",
    "    print('-------------------------Initiating the analysis-----------------------------------------------')\n",
    "    print(f'Total Number of Transactions are:  {df.shape[0]}')\n",
    "    result=begin_analysis(mapping_dict,columns_we_want,df,df.shape[0])\n",
    "    df2=pd.DataFrame.from_records(result)\n",
    "    df2=df2.transpose()\n",
    "    df2.reset_index(inplace=True)\n",
    "    print(df2.head(20))\n",
    "\n",
    "    print('-----------------------Analysis End Below Are The Results-----------------------------------')\n",
    "    while True:\n",
    "        file_name=input('Enter a file name to save the results in: ->')\n",
    "        if not file_name.strip():\n",
    "            print('File Name Cannot Be Empty')\n",
    "        else:\n",
    "            folder='ResultsFolder'\n",
    "            os.makedirs(folder,exist_ok=True)\n",
    "            file_path=os.path.join(folder,f'{file_name}.csv')\n",
    "            df2.to_csv(file_path,index=False)\n",
    "            print('Results has been saved to the folder...........')\n",
    "            break\n",
    "    print(\"Saving the Concated Data in another Files.....\")\n",
    "    \n",
    "    while True:\n",
    "        file_name=input('Enter a file name to save the results in: ->')\n",
    "        if not file_name.strip():\n",
    "            print('File Name Cannot Be Empty')\n",
    "        else:\n",
    "            folder='Appended File Folder'\n",
    "            os.makedirs(folder,exist_ok=True)\n",
    "            file_path=os.path.join(folder,f'{file_name}.csv')\n",
    "            df2=pl.from_pandas(df)\n",
    "            df2.to_csv(file_path,index=False)\n",
    "            print('Results has been saved to the folder...........')\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "924e6532",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking the input of the files:--->\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the Number of Master File We Have:  1\n",
      "Enter the file path for master file:  C:\\Users\\AnkitS-Simfoni\\Users\\ankit-Simfoni\\Automation Tasks\\Task 1 - By Ashish - Finalized\\Sunsource Mapping Raw data\\Sunsource Invoice_Concur August consolidation.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------Initiating the Mapping Process----------------------------------------\n",
      "We Will Be Creating Mapping For dict_keys(['Date', 'Spend', 'Currency', 'Invoice Number', 'Invoice Line Number', 'Supplier Name', 'Description']), Enter None If We Dont Have A Mapping Column For A Specific Column\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the mapping column for Date,(None if no mapping column):  Document Date\n",
      "Enter the mapping column for Spend,(None if no mapping column):  Spend\n",
      "Enter the mapping column for Currency,(None if no mapping column):  Document Currency\n",
      "Enter the mapping column for Invoice Number,(None if no mapping column):  Document Number\n",
      "Enter the mapping column for Invoice Line Number,(None if no mapping column):  Document Line Number\n",
      "Enter the mapping column for Supplier Name,(None if no mapping column):  Supplier Name\n",
      "Enter the mapping column for Description:   .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.'] not present in master file\n",
      "Choose From Index(['SrNo', 'ActualSrNo', 'Data Source', 'File Name', 'Source System',\n",
      "       'Entity Code', 'Entity Name', 'Entity City', 'Entity State',\n",
      "       'Entity Country', 'Entity Region', 'Document Number',\n",
      "       'Document Line Number', 'Document Date', 'Document Header Description',\n",
      "       'Document Line Description', 'Buyer Name', 'Payment Terms Code',\n",
      "       'Payment Terms Description', 'Supplier Document Number',\n",
      "       'Supplier Code', 'Supplier Name', 'Supplier Name (Normalized)',\n",
      "       'Supplier City', 'Supplier State', 'Supplier Country',\n",
      "       'Supplier Region', 'Supplier Tax ID', 'Document Unit price',\n",
      "       'Document Quantity', 'Document UOM', 'Document Currency',\n",
      "       'Amount in Document Currency', 'FX Rate', 'Spend', 'Cost Center Code',\n",
      "       'Cost Center Description', 'General Ledger Code',\n",
      "       'General Ledger Description', 'Material Code', 'Material Description',\n",
      "       'Material Group Code', 'Material Group Description', 'Contract Flag',\n",
      "       'Intercompany Flag', 'Scope', 'Supplier Commonality', 'Supplier Group',\n",
      "       'Invoice Group', 'Transaction Group', 'Addressability Flag',\n",
      "       'Category Level 0', 'Category Level 1', 'Category Level 2',\n",
      "       'Category Level 3', 'Category Level 4', 'Category Level 5',\n",
      "       'Category Level 6', 'Employee Last Name', 'cl_qa_flag',\n",
      "       'cl_training_set_flag', 'cl_cluster_id', 'source_name', 'custom_field1',\n",
      "       'custom_field2', 'custom_field3', 'custom_field4', 'custom_field5',\n",
      "       'QA flag', 'Posted Date', 'Sent for Payment Date', 'Detail', 'Batch ID',\n",
      "       'Sequence', 'Employee ID', 'Employee First Name', 'Expense Group ID',\n",
      "       'Operating Department Code', 'Company Name', 'Company Code',\n",
      "       'Division/Branch Name', 'Division/Branch Code', 'Department Name',\n",
      "       'Department Code', 'Report Name', 'Total Approved Amount',\n",
      "       'Reimbursement Currency', 'Payment Type', 'Project #', 'Name on Card',\n",
      "       'Last Four Account Digits', 'Merchant Code', 'Transaction Date',\n",
      "       'Code Company'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the mapping column for Description:   Document Header Description,Document Line Description,Payment Terms Description,Cost Center Description,General Ledger Description,Material Description,Material Group Description,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[''] not present in master file\n",
      "Choose From Index(['SrNo', 'ActualSrNo', 'Data Source', 'File Name', 'Source System',\n",
      "       'Entity Code', 'Entity Name', 'Entity City', 'Entity State',\n",
      "       'Entity Country', 'Entity Region', 'Document Number',\n",
      "       'Document Line Number', 'Document Date', 'Document Header Description',\n",
      "       'Document Line Description', 'Buyer Name', 'Payment Terms Code',\n",
      "       'Payment Terms Description', 'Supplier Document Number',\n",
      "       'Supplier Code', 'Supplier Name', 'Supplier Name (Normalized)',\n",
      "       'Supplier City', 'Supplier State', 'Supplier Country',\n",
      "       'Supplier Region', 'Supplier Tax ID', 'Document Unit price',\n",
      "       'Document Quantity', 'Document UOM', 'Document Currency',\n",
      "       'Amount in Document Currency', 'FX Rate', 'Spend', 'Cost Center Code',\n",
      "       'Cost Center Description', 'General Ledger Code',\n",
      "       'General Ledger Description', 'Material Code', 'Material Description',\n",
      "       'Material Group Code', 'Material Group Description', 'Contract Flag',\n",
      "       'Intercompany Flag', 'Scope', 'Supplier Commonality', 'Supplier Group',\n",
      "       'Invoice Group', 'Transaction Group', 'Addressability Flag',\n",
      "       'Category Level 0', 'Category Level 1', 'Category Level 2',\n",
      "       'Category Level 3', 'Category Level 4', 'Category Level 5',\n",
      "       'Category Level 6', 'Employee Last Name', 'cl_qa_flag',\n",
      "       'cl_training_set_flag', 'cl_cluster_id', 'source_name', 'custom_field1',\n",
      "       'custom_field2', 'custom_field3', 'custom_field4', 'custom_field5',\n",
      "       'QA flag', 'Posted Date', 'Sent for Payment Date', 'Detail', 'Batch ID',\n",
      "       'Sequence', 'Employee ID', 'Employee First Name', 'Expense Group ID',\n",
      "       'Operating Department Code', 'Company Name', 'Company Code',\n",
      "       'Division/Branch Name', 'Division/Branch Code', 'Department Name',\n",
      "       'Department Code', 'Report Name', 'Total Approved Amount',\n",
      "       'Reimbursement Currency', 'Payment Type', 'Project #', 'Name on Card',\n",
      "       'Last Four Account Digits', 'Merchant Code', 'Transaction Date',\n",
      "       'Code Company'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the mapping column for Description:   Document Header Description,Document Line Description,Payment Terms Description,Cost Center Description,General Ledger Description,Material Description,Material Group Description\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Initiating the analysis-----------------------------------------------\n",
      "Total Number of Transactions are:  22774\n",
      "                          index Percentage Population NA Count Comment  \\\n",
      "0                    ActualSrNo                 100.0        0    None   \n",
      "1           Addressability Flag                   0.0    22774    None   \n",
      "2   Amount in Document Currency                 100.0        0    None   \n",
      "3                      Batch ID                   0.0    22774    None   \n",
      "4                    Buyer Name             25.950645    16864    None   \n",
      "5              Category Level 0                   0.0    22774    None   \n",
      "6              Category Level 1                   0.0    22774    None   \n",
      "7              Category Level 2                   0.0    22774    None   \n",
      "8              Category Level 3                   0.0    22774    None   \n",
      "9              Category Level 4                   0.0    22774    None   \n",
      "10             Category Level 5                   0.0    22774    None   \n",
      "11             Category Level 6                   0.0    22774    None   \n",
      "12                 Code Company                   0.0    22774    None   \n",
      "13                 Company Code                   0.0    22774    None   \n",
      "14                 Company Name                   0.0    22774    None   \n",
      "15                Contract Flag                   0.0    22774    None   \n",
      "16             Cost Center Code             91.872311     1851    None   \n",
      "17      Cost Center Description                 100.0        0    None   \n",
      "18                     Currency                 100.0        0    None   \n",
      "19                  Data Source                 100.0        0    None   \n",
      "\n",
      "     Column Type  \n",
      "0   Good To Have  \n",
      "1   Good To Have  \n",
      "2   Good To Have  \n",
      "3   Good To Have  \n",
      "4   Good To Have  \n",
      "5   Good To Have  \n",
      "6   Good To Have  \n",
      "7   Good To Have  \n",
      "8   Good To Have  \n",
      "9   Good To Have  \n",
      "10  Good To Have  \n",
      "11  Good To Have  \n",
      "12  Good To Have  \n",
      "13  Good To Have  \n",
      "14  Good To Have  \n",
      "15  Good To Have  \n",
      "16  Good To Have  \n",
      "17     Important  \n",
      "18     Important  \n",
      "19  Good To Have  \n",
      "-----------------------Analysis End Below Are The Results-----------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a file name to save the results in: -> SunSource Results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results has been saved to the folder...........\n",
      "Saving the Concated Data in another Files.....\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a file name to save the results in: -> results\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[7], line 87\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m file_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     86\u001b[0m df2\u001b[38;5;241m=\u001b[39mpl\u001b[38;5;241m.\u001b[39mfrom_pandas(df)\n\u001b[1;32m---> 87\u001b[0m df2\u001b[38;5;241m.\u001b[39mto_csv(file_path,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResults has been saved to the folder...........\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39b5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
